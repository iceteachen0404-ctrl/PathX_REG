#!/usr/bin/env python3
"""
CoCaPrismæ¨¡å‹ä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•è®­ç»ƒå’Œä½¿ç”¨åŸºäºPrismæ¶æ„çš„CoCaæ¨¡å‹
"""

import torch
import numpy as np
from pathlib import Path

# å¯¼å…¥CoCaPrismæ¨¡å‹
from coca_pytorch_prism import CoCaPrism

# å¯¼å…¥BioGPT tokenizer
from transformers import BioGptTokenizer

def example_basic_usage():
    """åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹"""
    print("ğŸš€ CoCaPrismæ¨¡å‹åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    # 1. åˆ›å»ºæ¨¡å‹ï¼ˆä»HuggingFaceåŠ è½½é¢„è®­ç»ƒæƒé‡ï¼‰
    print("1. åˆ›å»ºæ¨¡å‹...")
    model = CoCaPrism(
        prism_model_name='paige-ai/Prism',
        caption_loss_weight=1.0,
        contrastive_loss_weight=1.0,
        frozen_prism=True,  # å†»ç»“Prismç»„ä»¶ï¼Œåªè®­ç»ƒå¯¹æ¯”å­¦ä¹ å¤´
    )
    
    print(f"   æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    print(f"   å¯è®­ç»ƒå‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
    
    # 2. å‡†å¤‡æ•°æ®
    print("\n2. å‡†å¤‡æ•°æ®...")
    batch_size = 2
    num_tiles = 10
    tile_dim = 2560
    seq_len = 20
    
    # æ¨¡æ‹Ÿtile embeddings
    tile_embeddings = torch.randn(batch_size, num_tiles, tile_dim)
    
    # æ¨¡æ‹Ÿæ–‡æœ¬tokens
    vocab_size = model.vocab_size
    text_tokens = torch.randint(0, vocab_size, (batch_size, seq_len))
    
    # åˆ›å»ºæ ‡ç­¾
    labels = text_tokens[:, 1:].contiguous()
    input_tokens = text_tokens[:, :-1].contiguous()
    
    print(f"   tile_embeddingså½¢çŠ¶: {tile_embeddings.shape}")
    print(f"   input_tokenså½¢çŠ¶: {input_tokens.shape}")
    print(f"   labelså½¢çŠ¶: {labels.shape}")
    
    # 3. å‰å‘ä¼ æ’­
    print("\n3. å‰å‘ä¼ æ’­...")
    with torch.no_grad():
        output = model(
            text=input_tokens,
            image_tokens=tile_embeddings,
            labels=labels,
            return_loss=True
        )
    
    print(f"   è¾“å‡ºå½¢çŠ¶:")
    print(f"     - logits: {output['logits'].shape}")
    print(f"     - text_embedding: {output['text_embedding'].shape}")
    print(f"     - image_embedding: {output['image_embedding'].shape}")
    print(f"     - sim: {output['sim'].shape}")
    print(f"   æŸå¤±å€¼:")
    print(f"     - æ€»æŸå¤±: {output['loss'].item():.4f}")
    print(f"     - CaptionæŸå¤±: {output['caption_loss'].item():.4f}")
    print(f"     - ContrastiveæŸå¤±: {output['contrastive_loss'].item():.4f}")
    
    # 4. æ–‡æœ¬ç”Ÿæˆ
    print("\n4. æ–‡æœ¬ç”Ÿæˆ...")
    with torch.no_grad():
        generated_tokens = model.generate(
            image_tokens=tile_embeddings,
            max_length=20,
            do_sample=True,
            temperature=0.7,
            top_p=0.9,
        )
    
    print(f"   ç”Ÿæˆçš„tokenå½¢çŠ¶: {generated_tokens.shape}")
    
    # 5. è§£ç ç”Ÿæˆçš„æ–‡æœ¬
    print("\n5. è§£ç ç”Ÿæˆçš„æ–‡æœ¬...")
    tokenizer = BioGptTokenizer.from_pretrained('microsoft/biogpt')
    
    for i, tokens in enumerate(generated_tokens):
        text = tokenizer.decode(tokens, skip_special_tokens=True)
        print(f"   æ ·æœ¬ {i+1}: {text}")
    
    print("\nâœ… åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹å®Œæˆï¼")

def example_training_workflow():
    """è®­ç»ƒå·¥ä½œæµç¤ºä¾‹"""
    print("\nğŸš€ CoCaPrismæ¨¡å‹è®­ç»ƒå·¥ä½œæµç¤ºä¾‹")
    print("=" * 50)
    
    # 1. åˆ›å»ºæ¨¡å‹
    print("1. åˆ›å»ºæ¨¡å‹...")
    model = CoCaPrism(
        prism_model_name='paige-ai/Prism',
        caption_loss_weight=1.0,
        contrastive_loss_weight=1.0,
        frozen_prism=True,
    )
    
    # 2. è®¾ç½®ä¼˜åŒ–å™¨ï¼ˆåªä¼˜åŒ–å¯è®­ç»ƒå‚æ•°ï¼‰
    print("2. è®¾ç½®ä¼˜åŒ–å™¨...")
    trainable_params = [p for p in model.parameters() if p.requires_grad]
    optimizer = torch.optim.AdamW(trainable_params, lr=1e-4)
    
    print(f"   å¯è®­ç»ƒå‚æ•°æ•°é‡: {sum(p.numel() for p in trainable_params):,}")
    print(f"   ä¼˜åŒ–å™¨å­¦ä¹ ç‡: {optimizer.param_groups[0]['lr']}")
    
    # 3. æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤
    print("\n3. æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤...")
    model.train()
    
    # å‡†å¤‡æ•°æ®
    batch_size = 2
    num_tiles = 10
    tile_dim = 2560
    seq_len = 20
    
    tile_embeddings = torch.randn(batch_size, num_tiles, tile_dim)
    text_tokens = torch.randint(0, model.vocab_size, (batch_size, seq_len))
    labels = text_tokens[:, 1:].contiguous()
    input_tokens = text_tokens[:, :-1].contiguous()
    
    # å‰å‘ä¼ æ’­
    output = model(
        text=input_tokens,
        image_tokens=tile_embeddings,
        labels=labels,
        return_loss=True
    )
    
    loss = output['loss']
    
    # åå‘ä¼ æ’­
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    print(f"   è®­ç»ƒæŸå¤±: {loss.item():.4f}")
    print(f"   CaptionæŸå¤±: {output['caption_loss'].item():.4f}")
    print(f"   ContrastiveæŸå¤±: {output['contrastive_loss'].item():.4f}")
    
    # 4. ä¿å­˜æ¨¡å‹
    print("\n4. ä¿å­˜æ¨¡å‹...")
    save_dir = "./example_checkpoint"
    model.save_pretrained(save_dir)
    
    # 5. åŠ è½½æ¨¡å‹
    print("\n5. åŠ è½½æ¨¡å‹...")
    loaded_model = CoCaPrism.from_pretrained(save_dir)
    
    print(f"   æ¨¡å‹åŠ è½½æˆåŠŸ")
    print(f"   æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in loaded_model.parameters()):,}")
    
    print("\nâœ… è®­ç»ƒå·¥ä½œæµç¤ºä¾‹å®Œæˆï¼")

def example_inference():
    """æ¨ç†ç¤ºä¾‹"""
    print("\nğŸš€ CoCaPrismæ¨¡å‹æ¨ç†ç¤ºä¾‹")
    print("=" * 50)
    
    # 1. åˆ›å»ºæ¨¡å‹
    print("1. åˆ›å»ºæ¨¡å‹...")
    model = CoCaPrism(
        prism_model_name='paige-ai/Prism',
        caption_loss_weight=1.0,
        contrastive_loss_weight=1.0,
        frozen_prism=True,
    )
    model.eval()
    
    # 2. å‡†å¤‡è¾“å…¥æ•°æ®
    print("\n2. å‡†å¤‡è¾“å…¥æ•°æ®...")
    batch_size = 1
    num_tiles = 15
    tile_dim = 2560
    
    # æ¨¡æ‹Ÿtile embeddings
    tile_embeddings = torch.randn(batch_size, num_tiles, tile_dim)
    
    # 3. ç”Ÿæˆæ–‡æœ¬
    print("\n3. ç”Ÿæˆæ–‡æœ¬...")
    with torch.no_grad():
        generated_tokens = model.generate(
            image_tokens=tile_embeddings,
            max_length=50,
            do_sample=True,
            temperature=0.7,
            top_p=0.9,
        )
    
    # 4. è§£ç æ–‡æœ¬
    print("\n4. è§£ç æ–‡æœ¬...")
    tokenizer = BioGptTokenizer.from_pretrained('microsoft/biogpt')
    
    for i, tokens in enumerate(generated_tokens):
        text = tokenizer.decode(tokens, skip_special_tokens=True)
        print(f"   ç”Ÿæˆçš„æè¿°: {text}")
    
    # 5. è®¡ç®—ç›¸ä¼¼åº¦
    print("\n5. è®¡ç®—ç›¸ä¼¼åº¦...")
    reference_text = "The patient has a malignant tumor in the breast tissue."
    
    # Tokenizeå‚è€ƒæ–‡æœ¬
    text_with_eos = reference_text + tokenizer.eos_token
    tokenized = tokenizer(
        text=text_with_eos,
        add_special_tokens=True,
        padding=False,
        return_tensors='pt',
        return_token_type_ids=False,
        return_attention_mask=False,
    )
    text_tokens = tokenized['input_ids']
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        output = model(
            text=text_tokens,
            image_tokens=tile_embeddings,
            return_embeddings=True
        )
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        text_embedding = output['text_embedding']
        image_embedding = output['image_embedding']
        
        similarity = torch.cosine_similarity(text_embedding, image_embedding, dim=1)
    
    print(f"   å‚è€ƒæ–‡æœ¬: {reference_text}")
    print(f"   ç›¸ä¼¼åº¦: {similarity.item():.4f}")
    
    print("\nâœ… æ¨ç†ç¤ºä¾‹å®Œæˆï¼")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ CoCaPrismæ¨¡å‹å®Œæ•´ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    
    try:
        # åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹
        example_basic_usage()
        
        # è®­ç»ƒå·¥ä½œæµç¤ºä¾‹
        example_training_workflow()
        
        # æ¨ç†ç¤ºä¾‹
        example_inference()
        
        print("\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡ŒæˆåŠŸï¼")
        print("\nğŸ“ ä½¿ç”¨è¯´æ˜:")
        print("1. åŸºæœ¬ä½¿ç”¨: åˆ›å»ºæ¨¡å‹ï¼Œå‡†å¤‡æ•°æ®ï¼Œè¿›è¡Œå‰å‘ä¼ æ’­")
        print("2. è®­ç»ƒå·¥ä½œæµ: è®¾ç½®ä¼˜åŒ–å™¨ï¼Œè®­ç»ƒæ¨¡å‹ï¼Œä¿å­˜å’ŒåŠ è½½")
        print("3. æ¨ç†: ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ç”Ÿæˆæ–‡æœ¬å’Œè®¡ç®—ç›¸ä¼¼åº¦")
        print("\nğŸ”§ å®é™…è®­ç»ƒ:")
        print("python train_coca_prism.py --embeddings_dir /path/to/embeddings --labels_file /path/to/labels.json")
        print("\nğŸ” å®é™…æ¨ç†:")
        print("python inference_coca_prism.py --checkpoint /path/to/checkpoint.pth --embeddings_file /path/to/embeddings.h5")
        
    except Exception as e:
        print(f"\nâŒ ç¤ºä¾‹è¿è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 